# Virtual Microgrid Segmentation
CS234 Project, Winter 2019

Project team: Bennet Meyers and Siobhan Powell

Contact the authors: bennetm or siobhan.powell at stanford dot edu

## Overview
Recent work has shown that microgrids can increase both grid flexibility and grid resiliency to unanticipated outages 
caused by events such as cyber attacks or extreme weather. A subclass of microgrids, known as “virtual 
islands”, occur when sections of a grid operate in isolation without any powerflow between them and the   larger grid, 
despite remaining physically connected. If a grid can can partition into virtual islands in anticipation of an incoming 
resiliency event, customers in those islands will be less likely to experience outages.

The goal of this project is to train a deep reinforcement learning (RL) agent to create and maintain as many small virtual 
islands as possible by operating a grids storage resources. The agent is rewarded for separating nodes from the external
grid connection and for splitting the graphs into as many segments as possible.  

We implement PG (policy gradient) and DDPG (deep deterministic policy gradient) algorithms to train the agent, and
apply it to a small test network. We find the DDPG performs the best, and it can successfully maintain microgrids even when
the loads are time varying and change between episodes. 

## The DDPG algorithm



## Structure of the Code

There are two main sides to the code: the network and the agents. 

The network is generated using Pandapower (https://pandapower.readthedocs.io/en/v1.6.1/index.html). 

The NetModel class in powerflow/pp_network.py maintains the network 
object throughout the simulation. It controls how the agent can interact with the network 
and with the powerflow simulations with methods to step in time, calculate the reward, reset the network, 
report the state to the agent, and update the network devices. These devices include uncontrollable and controllable devices: 
loads and static generators are set by an uncontrollable unknown feed;  the powers of storage and diesel generators are 
controlled by the agent. 

The initial network is generated by functions in powerflow/network_generation.py using configurations stored
in configs. Each config defines all the parameters behind one test set up, including those of the network and some 
elements of the agent set up.   

The ActorNetwork and CriticNetwork objects are created in agents/actor_network.py and agents/critic_network.py, and the 
DDPG object uses them to learn the optimal policy. DDPG manages the training of the actor/critic networks
and controls the interactions with the grid network model. 


  




#### Code organization
